{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vote Classifier Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifierI supports the following operations:\n",
      "  - self.classify(featureset)\n",
      "  - self.classify_many(featuresets)\n",
      "  - self.labels()\n",
      "  - self.prob_classify(featureset)\n",
      "  - self.prob_classify_many(featuresets)\n"
     ]
    }
   ],
   "source": [
    "nltk.usage(nltk.classify.ClassifierI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time a classifier selects a category for a document, it inserts the **category into an array**. That is its vote. So you end up with an array of 'votes' (vote can be positive or negative).\n",
    "\n",
    "Now for example, if there are 10 classifiers and 7 voted 'pos', while 3 voted 'neg'. Then it uses mode of the array which brings back the most frequently occurring value in the array ('pos' in this example). Then it finds the number of times that value 'pos' occurs in the array. It divides that number of occurences number of pos (which is 7) by the total (which is 10) to give 70% as the confidence. Because 70% of the classifiers voted (classified) the document that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for c in self._classifiers:\n",
    "            v = c.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data and Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code we have done below mentioned operations\n",
    "- Read from the files.\n",
    "- appended reviews to documents list along with its **classified category**.\n",
    "- **Tokenized** words sequentially line by line using `pos_tag` to append words that are only **adjective**.\n",
    "- Saved our document using pickle.\n",
    "- Created a **frequency distribution** of appended words to mark out the 5000 most occured words to be used for training.\n",
    "- Defined a function that takes document as argument and returns a tuple with each word against a boolen value for being in most occured or word_features list.\n",
    "- Created a featuresets list that has data to be trained in the format created by above points.\n",
    "- Shuffled and Splitted the data into training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10664\n"
     ]
    }
   ],
   "source": [
    "#open the files\n",
    "short_pos = open(\"positive.txt\",\"r\").read()\n",
    "short_neg = open(\"negative.txt\",\"r\").read()\n",
    "\n",
    "\n",
    "all_words = []\n",
    "documents = []\n",
    "\n",
    "\n",
    "#  j is adject, r is adverb, and v is verb\n",
    "\n",
    "allowed_word_types = [\"J\"]\n",
    "\n",
    "for p in short_pos.split('\\n'):\n",
    "    documents.append( (p, \"pos\") )\n",
    "    words = word_tokenize(p)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "    \n",
    "for p in short_neg.split('\\n'):\n",
    "    documents.append( (p, \"neg\") )\n",
    "    words = word_tokenize(p)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "\n",
    "\n",
    "save_documents = open(\"pickled_algos/pickled_documents.pickle\",\"wb\")\n",
    "pickle.dump(documents, save_documents)\n",
    "save_documents.close()\n",
    "\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "\n",
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "\n",
    "save_word_features = open(\"pickled_algos/word_features5k.pickle\",\"wb\")\n",
    "pickle.dump(word_features, save_word_features)\n",
    "save_word_features.close()\n",
    "\n",
    "\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "print(len(featuresets))\n",
    "\n",
    "testing_set = featuresets[10000:]\n",
    "training_set = featuresets[:10000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our data using **Sklearn models** we have to convert our the model that sklearn model provides that is somewhat acceptable to operatins done using **nltk** library and therefore each and every model that we have imported using sklearn module has been fitted to a method `SklearnClassifier()` that is provided and can be imported using nltk module.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is appreciable to store your models using **pickle** to avoid training multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 73.19277108433735\n",
      "Most Informative Features\n",
      "              engrossing = True              pos : neg    =     20.4 : 1.0\n",
      "               inventive = True              pos : neg    =     15.7 : 1.0\n",
      "                 generic = True              neg : pos    =     15.6 : 1.0\n",
      "                mediocre = True              neg : pos    =     15.6 : 1.0\n",
      "                 routine = True              neg : pos    =     15.6 : 1.0\n",
      "                    flat = True              neg : pos    =     14.6 : 1.0\n",
      "              refreshing = True              pos : neg    =     14.4 : 1.0\n",
      "                    warm = True              pos : neg    =     13.0 : 1.0\n",
      "                  boring = True              neg : pos    =     12.7 : 1.0\n",
      "                mindless = True              neg : pos    =     11.6 : 1.0\n",
      "             mesmerizing = True              pos : neg    =     11.0 : 1.0\n",
      "               wonderful = True              pos : neg    =     11.0 : 1.0\n",
      "                  stupid = True              neg : pos    =     11.0 : 1.0\n",
      "                    dull = True              neg : pos    =     10.4 : 1.0\n",
      "                 intense = True              pos : neg    =     10.3 : 1.0\n",
      "MNB_classifier accuracy percent: 73.19277108433735\n",
      "BernoulliNB_classifier accuracy percent: 73.3433734939759\n",
      "LogisticRegression_classifier accuracy percent: 71.08433734939759\n",
      "LinearSVC_classifier accuracy percent: 67.62048192771084\n",
      "SGDClassifier accuracy percent: 70.33132530120481\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, testing_set))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "###############\n",
    "save_classifier = open(\"pickled_algos/originalnaivebayes5k.pickle\",\"wb\")\n",
    "pickle.dump(classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/MNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(MNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/BernoulliNB_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(BernoulliNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/LogisticRegression_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LogisticRegression_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/LinearSVC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(LinearSVC_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "SGDC_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDC_classifier.train(training_set)\n",
    "print(\"SGDClassifier accuracy percent:\",nltk.classify.accuracy(SGDC_classifier, testing_set)*100)\n",
    "\n",
    "save_classifier = open(\"pickled_algos/SGDC_classifier5k.pickle\",\"wb\")\n",
    "pickle.dump(SGDC_classifier, save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Voted Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based upon all the above mentioned classifiers we are going to create a vote classifier that takes in the **category** categorised by vote of majority of classifiers against minority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "voted_classifier = VoteClassifier(\n",
    "                                  classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.04216867469879"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(voted_classifier,testing_set)*100 # accuracy of voted_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Sentiment of a movie review "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that takes in a single review to classify it as **positive** or **negative** using 5 different classifiers out of which the one's in fovour of majority are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    feats = find_features(text)\n",
    "    print('Classifiers in favour of',voted_classifier.classify(feats),':',voted_classifier.confidence(feats)*5)\n",
    "    return voted_classifier.classify(feats),voted_classifier.confidence(feats)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Sentiment of movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers in favour of pos : 5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('pos', 100.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('This movie is awesome.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers in favour of neg : 5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('neg', 100.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('This movie is crap.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers in favour of neg : 5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('neg', 100.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('Acting was not upto the mark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers in favour of neg : 5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('neg', 100.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"This movie was utter junk. There were absolutely 0 pythons. I don't see what the point was at all. Horrible movie, 0/10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers in favour of pos : 3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('pos', 60.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment('moderately good')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
